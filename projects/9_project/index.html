<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Dual-Decoder LLaMa Transformer for Mechanism Synthesis Using Coupler Curve Images | Anar Nurizada </title> <meta name="author" content="Anar Nurizada"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://anarnuri.github.io/projects/9_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Anar</span> Nurizada </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post-container"> <header class="post-header"> <h1 class="post-title">Dual-Decoder LLaMa Transformer for Mechanism Synthesis Using Coupler Curve Images</h1> </header> <article class="post-content"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/transformer-480.webp 480w,/assets/img/transformer-800.webp 800w,/assets/img/transformer-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/transformer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Overview of double-decoder Transformer Model" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Overview: The double-decoder Transformer model processes input coupler curves and mechanism type embeddings, enabling the generation of diverse mechanisms. The encoder captures the spatial features, while the dual decoders independently predict joint coordinates for mechanism synthesis. </div> <p><a href="https://github.com/anarnuri/path_generation_transformer" rel="external nofollow noopener" target="_blank"><strong>Access the Full Code on GitHub</strong></a></p> <h2 id="overview">Overview</h2> <p>Designing mechanisms capable of following specific trajectories, known as coupler curves, is a core challenge in mechanical engineering and robotics. Mechanisms are essential in applications ranging from robotic arms to automated manufacturing processes. However, traditional methods for mechanism synthesis rely heavily on analytical techniques, which are:</p> <ol> <li> <strong>Time-Consuming</strong>: Solving complex equations for mechanism synthesis is computationally expensive, especially for higher-order mechanisms.</li> <li> <strong>Single-Solution Oriented</strong>: These methods typically provide only one mechanism design for a given coupler curve.</li> <li> <strong>Limited in Complexity</strong>: Analytical approaches struggle with mechanisms that have a large number of joints or require intricate trajectories.</li> </ol> <h3 id="motivation-for-a-machine-learning-approach">Motivation for a Machine Learning Approach</h3> <p>Machine learning offers an innovative alternative to traditional methods, enabling faster and more diverse solutions. By leveraging data-driven models, engineers can explore a wider range of mechanism designs and automate the synthesis process. This project introduces a <strong>Dual-Decoder Transformer</strong> model, designed specifically for mechanism synthesis. Key innovations include:</p> <ul> <li> <strong>Coupler Curves as Images</strong>: Input trajectories are represented as grayscale images, enabling the use of convolutional layers for spatial feature extraction.</li> <li> <strong>Mechanism Type Embeddings</strong>: Each mechanism type is encoded as a unique feature vector to condition the modelâ€™s output.</li> <li> <strong>Joint Coordinates as Output</strong>: Mechanisms are represented as Cartesian coordinates of their joints, split into two independent parts for simplified learning.</li> </ul> <p><a href="https://github.com/anarnuri/path_generation_transformer" rel="external nofollow noopener" target="_blank"><strong>Access the Full Code on GitHub</strong></a></p> <hr> <h2 id="key-contributions">Key Contributions</h2> <ol> <li> <p><strong>Mechanism Type Conditioning</strong>:</p> <ul> <li>Introduces a dedicated embedding layer for mechanism types, enabling the model to generate designs specific to the input type.</li> </ul> </li> <li> <p><strong>Dual-Decoder Architecture</strong>:</p> <ul> <li>Employs two independent decoders: <ul> <li>The <strong>first decoder</strong> predicts the first set of joint coordinates.</li> <li>The <strong>second decoder</strong> predicts the second set of joint coordinates.</li> </ul> </li> <li>This modular design improves performance for complex mechanisms.</li> </ul> </li> <li> <p><strong>Advanced Loss Masking</strong>:</p> <ul> <li>Implements a masked Mean Squared Error (MSE) loss to handle variable-length sequences and padding tokens.</li> </ul> </li> <li> <p><strong>Efficiency and Scalability</strong>:</p> <ul> <li>Processes coupler curve images efficiently through patch embeddings and scaled positional encodings.</li> <li>Designed to handle a wide range of mechanism types and complexities.</li> </ul> </li> </ol> <hr> <h2 id="iterative-development-process">Iterative Development Process</h2> <p>The development process involved several iterations to refine the architecture and improve performance:</p> <h3 id="initial-attempts">Initial Attempts</h3> <p>The project began with a single-decoder Transformer model inspired by natural language processing. However, early experiments revealed significant limitations:</p> <ul> <li> <strong>Poor Performance on Complex Mechanisms</strong>: The single decoder struggled with mechanisms having more than six joints.</li> <li> <strong>Limited Scalability</strong>: Increasing the model size improved results slightly but introduced overfitting and longer training times.</li> </ul> <h3 id="integration-of-llama-features">Integration of LLAMA Features</h3> <p>To address these challenges, features from the LLAMA architecture were integrated:</p> <ol> <li> <strong>RMS Normalization</strong>: <ul> <li>Improved training stability and model convergence.</li> </ul> </li> <li> <strong>Scaled Embeddings</strong>: <ul> <li>Enhanced input and positional embeddings to capture spatial relationships effectively.</li> </ul> </li> <li> <strong>Dynamic Causal Masking</strong>: <ul> <li>Ensured that predictions were generated step-by-step during training and inference.</li> </ul> </li> </ol> <h3 id="introduction-of-dual-decoders">Introduction of Dual Decoders</h3> <p>A major breakthrough came with the introduction of two independent decoders. This design allowed the model to handle mechanisms of varying complexity by splitting the task into two smaller, more manageable subtasks.</p> <hr> <h2 id="methodology">Methodology</h2> <h3 id="input-representation">Input Representation</h3> <ol> <li> <p><strong>Coupler Curves as Images</strong>:</p> <ul> <li>Each trajectory is represented as a 2D grayscale image, divided into patches of fixed size.</li> <li>A convolutional layer extracts features from these patches, which are embedded into a fixed-dimensional vector.</li> </ul> </li> <li> <p><strong>Mechanism Type Embeddings</strong>:</p> <ul> <li>Each mechanism type is represented as a unique vector using a learnable embedding layer.</li> <li>The embedding is added to the input sequence to condition the model on the desired mechanism type.</li> </ul> </li> </ol> <h3 id="model-architecture">Model Architecture</h3> <ol> <li> <p><strong>Transformer Encoder</strong>:</p> <ul> <li>Processes the embedded input sequence (coupler curve patches + mechanism type embedding).</li> <li>Captures spatial relationships and encodes them into a latent representation.</li> </ul> </li> <li> <p><strong>Dual Decoders</strong>:</p> <ul> <li>Each decoder independently predicts one part of the mechanism (first and second sets of joint coordinates).</li> <li>Cross-attention layers allow the decoders to leverage information from the encoderâ€™s latent representation.</li> </ul> </li> <li> <p><strong>Projection Layers</strong>:</p> <ul> <li>Map the decoder outputs back to Cartesian coordinates.</li> </ul> </li> </ol> <h3 id="training-process">Training Process</h3> <ol> <li> <p><strong>Masked MSE Loss</strong>:</p> <ul> <li>Handles variable-length sequences by masking padding tokens during loss computation.</li> </ul> <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mse_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">mask_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="o">~</span><span class="p">(</span><span class="n">targets</span> <span class="o">==</span> <span class="n">mask_value</span><span class="p">).</span><span class="nf">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">expand_as</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    <span class="n">masked_predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">masked_targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">mse_loss</span><span class="p">(</span><span class="n">masked_predictions</span><span class="p">,</span> <span class="n">masked_targets</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">"</span><span class="s">mean</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div> </div> </li> <li> <p><strong>Optimization</strong>:</p> <ul> <li>The model is trained using the Adam optimizer with a learning rate scheduler.</li> </ul> </li> <li> <p><strong>Dynamic Causal Masking</strong>:</p> <ul> <li>Applied during decoding to ensure stepwise predictions.</li> </ul> </li> </ol> <hr> <h2 id="inference-process">Inference Process</h2> <p>During inference, the model generates mechanism designs using a conditional greedy decoding approach:</p> <ol> <li> <p><strong>Encoding</strong>:</p> <ul> <li>The coupler curve image is encoded along with the mechanism type embedding.</li> </ul> </li> <li> <p><strong>Decoding</strong>:</p> <ul> <li>Each decoder independently predicts its part of the mechanism, conditioned on the encoderâ€™s latent representation.</li> </ul> </li> <li> <p><strong>Stopping Condition</strong>:</p> <ul> <li>Decoding halts when an End-of-Sequence (EOS) token is detected.</li> </ul> </li> </ol> <h3 id="code-highlights-for-inference">Code Highlights for Inference</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">greedy_decode_conditional</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">mech_type</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">eos_token</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])):</span>
    <span class="n">encoder_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">mech_type</span><span class="p">)</span>
    <span class="n">decoder_input_first</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">decoder_input_second</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Decoding for both decoders
</span>    <span class="k">while</span> <span class="n">decoder_input_first</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_len</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:</span>
        <span class="bp">...</span>
    <span class="k">while</span> <span class="n">decoder_input_second</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_len</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:</span>
        <span class="bp">...</span>
</code></pre></div></div> <hr> <h2 id="applications">Applications</h2> <ol> <li> <p><strong>Robotics</strong>:</p> <ul> <li>Generates diverse designs for robotic mechanisms, such as arms and grippers.</li> </ul> </li> <li> <p><strong>Industrial Design</strong>:</p> <ul> <li>Facilitates rapid prototyping of mechanisms for manufacturing.</li> </ul> </li> <li> <p><strong>Education</strong>:</p> <ul> <li>Provides a framework for teaching mechanism synthesis concepts using advanced machine learning techniques.</li> </ul> </li> </ol> <hr> <h2 id="future-directions">Future Directions</h2> <ol> <li> <p><strong>Intra-Type Diversity</strong>:</p> <ul> <li>Extend the model to generate multiple mechanisms within the same type.</li> </ul> </li> <li> <p><strong>Scalability</strong>:</p> <ul> <li>Adapt the architecture to handle mechanisms with more joints and higher complexities.</li> </ul> </li> <li> <p><strong>Optimization Frameworks</strong>:</p> <ul> <li>Integrate the model with optimization algorithms for real-time design applications.</li> </ul> </li> <li> <p><strong>Explainability</strong>:</p> <ul> <li>Develop visualizations to interpret the modelâ€™s attention mechanisms and latent space.</li> </ul> </li> </ol> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Anar Nurizada. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: April 14, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>