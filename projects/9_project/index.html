<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Mechformer. A Dual-Decoder Transformer with RMSNorm and SwiGLU for Mechanism Synthesis | Anar Nurizada </title> <meta name="author" content="Anar Nurizada"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://anarnuri.github.io/projects/9_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Anar</span> Nurizada </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post-container"> <header class="post-header"> <h1 class="post-title">Mechformer. A Dual-Decoder Transformer with RMSNorm and SwiGLU for Mechanism Synthesis</h1> </header> <article class="post-content"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/transformer-480.webp 480w,/assets/img/transformer-800.webp 800w,/assets/img/transformer-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/transformer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Overview of double-decoder Transformer Model" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Overview: The enhanced double-decoder Transformer model processes coupler curve images and mechanism type embeddings to generate diverse mechanism designs. The encoder captures spatial features, while the dual decoders predict joint coordinates, leveraging improved normalization, gating mechanisms, and robust attention modules. </div> <p><a href="https://github.com/anarnuri/path_generation_transformer" rel="external nofollow noopener" target="_blank"><strong>Access the Full Code on GitHub</strong></a></p> <h2 id="overview">Overview</h2> <p>Designing mechanisms that accurately follow complex trajectories (coupler curves) remains a foundational challenge in mechanical design and robotics. Traditional synthesis methods rely on solving analytical equations, which are:</p> <ol> <li> <strong>Computationally Intensive</strong>: Especially for higher-order mechanisms with many joints.</li> <li> <strong>Single-Result Oriented</strong>: Typically offering just one valid mechanism per coupler curve.</li> <li> <strong>Limited Flexibility</strong>: Struggle to generalize to mechanisms with complex or novel configurations.</li> </ol> <h3 id="motivation-for-a-machine-learning-approach">Motivation for a Machine Learning Approach</h3> <p>This project introduces a <strong>Dual-Decoder Transformer</strong> model that reimagines the synthesis pipeline. By leveraging deep learning, we can automate the generation of diverse and complex mechanisms, speeding up design iterations and broadening the search space. Key features of the model include:</p> <ul> <li> <strong>Coupler Curves as Images</strong>: Trajectories are input as grayscale images, allowing the encoder to extract spatial features effectively.</li> <li> <strong>Mechanism Type Conditioning</strong>: Each mechanism type is embedded into a feature vector, enabling the model to tailor its outputs accordingly.</li> <li> <strong>Coordinate Prediction</strong>: Mechanisms are represented by Cartesian coordinates of joints, split into two independently predicted parts for clarity and control.</li> </ul> <p>This model treats the mechanism as a sequence of tokens, where each token represents a joint in the mechanism. This tokenization approach allows the model to easily scale to mechanisms with a higher number of joints. Currently, the model can handle up to 20 joints, and its architecture is designed to accommodate even larger mechanisms by adjusting token length and model capacity. The modularity of the design, with independent decoders for each set of joint coordinates, further enhances scalability. As the number of joints increases, the model’s performance remains consistent, making it suitable for mechanisms of varying complexity without significant modifications. This scalability makes it a flexible solution for future applications that may involve more intricate mechanism designs.</p> <h2 id="key-enhancements">Key Enhancements</h2> <ol> <li> <p><strong>RMSNorm for Stability</strong>:</p> <ul> <li>The model replaces standard LayerNorm with <strong>RMSNorm</strong>, which normalizes inputs based on their root mean square. This improves training stability and convergence speed.</li> </ul> </li> <li> <p><strong>SwiGLU-inspired FeedForwardBlock</strong>:</p> <ul> <li>The feedforward block incorporates a <strong>Swish-Gated Linear Unit (SwiGLU)</strong> style mechanism: two parallel linear projections, where one is passed through a SiLU (swish) activation and multiplied element-wise with the other. This gating mechanism boosts expressiveness and non-linearity.</li> </ul> </li> <li> <p><strong>Modular Attention Mechanism</strong>:</p> <ul> <li>The attention layers now include <strong>dynamic masking</strong> capabilities, ensuring flexible handling of variable-length sequences and proper autoregressive decoding when needed.</li> </ul> </li> <li> <p><strong>Mixture of Experts (MoE) Integration</strong>:</p> <ul> <li>A MoE layer is included within the Transformer blocks to dynamically route information through multiple expert networks. This enables the model to specialize different parts of the network for various mechanism types and complexities, improving both flexibility and performance.</li> </ul> </li> <li> <p><strong>Enhanced Input Processing</strong>:</p> <ul> <li> <strong>Input Embeddings</strong>: Raw coupler curve images are patch-embedded using a linear projection and scaled by the square root of the model’s dimensionality.</li> <li> <strong>Positional Encoding</strong>: Sinusoidal positional encodings are precomputed and added to the embeddings, preserving sequence order.</li> </ul> </li> <li> <p><strong>Better Initialization</strong>:</p> <ul> <li>All linear layers are initialized with <strong>Xavier uniform initialization</strong>, promoting stable gradient flow from the start of training.</li> </ul> </li> <li> <p><strong>Clean Modular Design</strong>:</p> <ul> <li>Each component (embeddings, encoder, decoders, attention, normalization) is implemented as a separate, reusable module for ease of experimentation and future extension.</li> </ul> </li> </ol> <h2 id="iterative-development-process">Iterative Development Process</h2> <h3 id="early-exploration">Early Exploration</h3> <p>We began with a single-decoder Transformer adapted from NLP, but it quickly hit limitations:</p> <ul> <li> <strong>Inadequate Generalization</strong>: Struggled with mechanisms involving more than six joints.</li> <li> <strong>Scalability Issues</strong>: Larger models led to overfitting and diminishing returns.</li> </ul> <h3 id="key-architectural-shifts">Key Architectural Shifts</h3> <ul> <li> <strong>RMSNorm Integration</strong>: Replacing LayerNorm enhanced training consistency and reduced sensitivity to learning rate schedules.</li> <li> <strong>Dual-Decoders</strong>: Splitting predictions into two decoders provided modularity and improved performance on complex mechanism synthesis tasks.</li> <li> <strong>Gated Feedforward Blocks</strong>: Introducing SwiGLU-like structures allowed the model to model intricate joint relationships more effectively.</li> </ul> <h2 id="methodology">Methodology</h2> <h3 id="input">Input</h3> <ol> <li> <strong>Coupler Curve Images</strong>: <ul> <li>Converted to patches and embedded using a linear layer.</li> </ul> </li> <li> <strong>Mechanism Type Embeddings</strong>: <ul> <li>Learned embeddings added to each patch sequence to condition the model.</li> </ul> </li> </ol> <h3 id="model">Model</h3> <ul> <li> <strong>Encoder</strong>: <ul> <li>Processes combined embeddings, capturing spatial and contextual information.</li> </ul> </li> <li> <strong>Dual Decoders</strong>: <ul> <li>Independently predict the two halves of the joint coordinate set, each with cross-attention to the encoder’s output.</li> </ul> </li> <li> <strong>Projection Layers</strong>: <ul> <li>Map decoder outputs to 2D Cartesian coordinates.</li> </ul> </li> </ul> <h3 id="training">Training</h3> <ul> <li> <p><strong>Loss Function</strong>:<br> Masked MSE loss handles padding efficiently:</p> <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mse_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">mask_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="o">~</span><span class="p">(</span><span class="n">targets</span> <span class="o">==</span> <span class="n">mask_value</span><span class="p">).</span><span class="nf">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">expand_as</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    <span class="n">masked_predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">masked_targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">mse_loss</span><span class="p">(</span><span class="n">masked_predictions</span><span class="p">,</span> <span class="n">masked_targets</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">"</span><span class="s">mean</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div> </div> </li> </ul> <ol> <li> <p><strong>Optimization</strong>:</p> <ul> <li>The model is trained using the Adam optimizer with a learning rate scheduler.</li> </ul> </li> <li> <p><strong>Dynamic Causal Masking</strong>:</p> <ul> <li>Applied during decoding to ensure stepwise predictions.</li> </ul> </li> </ol> <hr> <h2 id="inference-process">Inference Process</h2> <p>During inference, the model generates mechanism designs using a conditional greedy decoding approach:</p> <ol> <li> <p><strong>Encoding</strong>:</p> <ul> <li>The coupler curve image is encoded along with the mechanism type embedding.</li> </ul> </li> <li> <p><strong>Decoding</strong>:</p> <ul> <li>Each decoder independently predicts its part of the mechanism, conditioned on the encoder’s representation.</li> </ul> </li> <li> <p><strong>Stopping Condition</strong>:</p> <ul> <li>Decoding halts when an End-of-Sequence (EOS) token is detected.</li> </ul> </li> </ol> <h3 id="code-highlights-for-inference">Code Highlights for Inference</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">greedy_decode_conditional</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">mech_type</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">eos_token</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])):</span>
    <span class="n">encoder_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">mech_type</span><span class="p">)</span>
    <span class="n">decoder_input_first</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">decoder_input_second</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Decoding for both decoders
</span>    <span class="k">while</span> <span class="n">decoder_input_first</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_len</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:</span>
        <span class="bp">...</span>
    <span class="k">while</span> <span class="n">decoder_input_second</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_len</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:</span>
        <span class="bp">...</span>
</code></pre></div></div> <hr> <h2 id="applications">Applications</h2> <ol> <li> <p><strong>Robotics</strong>:</p> <ul> <li>Generates diverse designs for robotic mechanisms, such as arms and grippers.</li> </ul> </li> <li> <p><strong>Industrial Design</strong>:</p> <ul> <li>Facilitates rapid prototyping of mechanisms for manufacturing.</li> </ul> </li> <li> <p><strong>Education</strong>:</p> <ul> <li>Provides a framework for teaching mechanism synthesis concepts using advanced machine learning techniques.</li> </ul> </li> </ol> <hr> <h2 id="future-directions">Future Directions</h2> <ol> <li> <p><strong>Intra-Type Diversity</strong>:</p> <ul> <li>Extend the model to generate multiple mechanisms within the same type.</li> </ul> </li> <li> <p><strong>Optimization Frameworks</strong>:</p> <ul> <li>Integrate the model with optimization algorithms for real-time design applications.</li> </ul> </li> <li> <p><strong>Explainability</strong>:</p> <ul> <li>Develop visualizations to interpret the model’s attention mechanisms and latent space.</li> </ul> </li> </ol> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Anar Nurizada. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: September 09, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>